{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab-9(Speech).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iam-pattan/DL-lab/blob/main/Lab_9(Speech).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sb_ulBynLySx"
      },
      "source": [
        "https://github.com/PacktPublishing/Python-Deep-Learning-Cookbook/blob/master/Chapter09/Chapter%209%20-%20Identifying%20speakers%20with%20voice%20recognition.ipynb\n",
        "\n",
        "https://github.com/aravindpai/Speech-Recognition/blob/master/Speech%20Recognition.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owByQ6-UE3Yl"
      },
      "source": [
        "# CLASS CODE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQ2xWNToKHya"
      },
      "source": [
        "import glob\n",
        "import numpy as np\n",
        "import random\n",
        "import librosa\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnwFPSOOKvH7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8652d839-74ed-4e3e-e2bd-8f0919931ef8"
      },
      "source": [
        "# !wget https://zenodo.org/record/1342401/files/Jakobovski/free-spoken-digit-dataset-v1.0.8.zip\n",
        "# !unzip free-spoken-digit-dataset-v1.0.8.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-30 10:05:17--  https://zenodo.org/record/1342401/files/Jakobovski/free-spoken-digit-dataset-v1.0.8.zip\n",
            "Resolving zenodo.org (zenodo.org)... 137.138.76.77\n",
            "Connecting to zenodo.org (zenodo.org)|137.138.76.77|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7273063 (6.9M) [application/octet-stream]\n",
            "Saving to: ‘free-spoken-digit-dataset-v1.0.8.zip.3’\n",
            "\n",
            "free-spoken-digit-d 100%[===================>]   6.94M  2.83MB/s    in 2.5s    \n",
            "\n",
            "2021-04-30 10:05:22 (2.83 MB/s) - ‘free-spoken-digit-dataset-v1.0.8.zip.3’ saved [7273063/7273063]\n",
            "\n",
            "Archive:  free-spoken-digit-dataset-v1.0.8.zip\n",
            "e9e1155aba3a0c632823b813aa74918807644509\n",
            "replace Jakobovski-free-spoken-digit-dataset-e9e1155/.gitignore? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUpRMJ6uKvO4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7075eed0-fed5-488d-bff6-5259c8b0d1ea"
      },
      "source": [
        "SEED = 123\n",
        "datapath = \"/content/Jakobovski-free-spoken-digit-dataset-e9e1155/recordings/\"\n",
        "'/content/Jakobovski-free-spoken-digit-dataset-e9e1155'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/Jakobovski-free-spoken-digit-dataset-e9e1155'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FoZ3YBu9KvSY",
        "outputId": "9fcbd640-e87f-4201-a34d-7b334c0b5a74"
      },
      "source": [
        "files = glob.glob(datapath+\"*.wav\")\n",
        "len(files)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1500"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fb5565IKvWq",
        "outputId": "feed8b2e-9105-4b9b-c32e-0ae9ef4de735"
      },
      "source": [
        "X_train, X_val = train_test_split(files, test_size=0.2, random_state=SEED)\n",
        "\n",
        "print('# Training examples: {}'.format(len(X_train)))\n",
        "print('# Validation examples: {}'.format(len(X_val)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# Training examples: 1200\n",
            "# Validation examples: 300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fmknQz_Kvbf",
        "outputId": "7db09b84-4cb0-4822-d487-80fba7fe6854"
      },
      "source": [
        "labels = []\n",
        "for i in range(len(X_train)):\n",
        "    label = X_train[i].split('/')[-1].split('_')[1]\n",
        "    if label not in labels:\n",
        "        labels.append(label)\n",
        "print(labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['nicolas', 'theo', 'jackson']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IClV0nlzKvgV"
      },
      "source": [
        "label_binarizer = LabelBinarizer()\n",
        "label_binarizer.fit(list(set(labels)))\n",
        "\n",
        "def one_hot_encode(x): return label_binarizer.transform(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opKpAg20Kvjo"
      },
      "source": [
        "n_features = 20\n",
        "max_length = 80\n",
        "n_classes = len(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygFVfgvpLID0"
      },
      "source": [
        "def generator(number):\n",
        "    i=0\n",
        "    while i< number:\n",
        "        i = i+1\n",
        "        if i%2==0:\n",
        "            yield i"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPg1Cd3jNAuS"
      },
      "source": [
        "datagen = generator(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-ehcku8QnFs",
        "outputId": "c9ab5bce-b81b-4e00-cd15-c797d58bdde4"
      },
      "source": [
        "next(datagen)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6V5XEt2LIHe"
      },
      "source": [
        "def batch_generator(data, batch_size=16):\n",
        "    while 1:\n",
        "        random.shuffle(data)\n",
        "        X, y = [], []\n",
        "        for i in range(batch_size):\n",
        "            wav = data[i]\n",
        "            wave, sr = librosa.load(wav, mono=True)\n",
        "            label = wav.split('/')[-1].split('_')[1]\n",
        "            y.append(label)\n",
        "            mfcc = librosa.feature.mfcc(wave, sr)\n",
        "            mfcc = np.pad(mfcc, ((0,0), (0, max_length-len(mfcc[0]))), mode='constant', constant_values=0) \n",
        "            X.append(np.array(mfcc))\n",
        "        yield np.array(X), np.array(one_hot_encode(y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFfBZe9-LILu"
      },
      "source": [
        "train_datagen = batch_generator(X_train, batch_size=32)\n",
        "val_datagen = batch_generator(X_val, batch_size = 4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_nGjOfRLIPh"
      },
      "source": [
        "#Model DEFN\n",
        "input_shape = (n_features, max_length)\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.LSTM(256, return_sequences=True, input_shape=input_shape,\n",
        "dropout=0.5))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "model.add(tf.keras.layers.Dense(n_classes, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5plFssvKvm5"
      },
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGHw5LQtLc2o"
      },
      "source": [
        "callbacks = [tf.keras.callbacks.ModelCheckpoint('SPEAKER_best_model_.hdf5', save_best_only=True),\n",
        "            tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=2)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-i391u1Lc60"
      },
      "source": [
        "# help(model.fit)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kAG_59KLc-9"
      },
      "source": [
        "history = model.fit(\n",
        "    train_datagen, \n",
        "    steps_per_epoch=10,\n",
        "    epochs=3,\n",
        "    validation_data=val_datagen,\n",
        "    validation_steps=5,\n",
        "    validation_freq=1,\n",
        "    verbose=1\n",
        "    # callbacks = callbacks\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DsfluSpLdDu"
      },
      "source": [
        "def testSample(filename,model):\n",
        "  # Read the WAV file and transform it into mfcc\n",
        "  print(filename)\n",
        "  max_length = 80\n",
        "  wave, sr = librosa.load(filename, mono=True)\n",
        "  mfcc = librosa.feature.mfcc(wave, sr)\n",
        "  if(len(mfcc[0]) < 60 ):\n",
        "    mfcc = np.pad(mfcc, ((0,0), (0, max_length-len(mfcc[0]))), mode='constant', constant_values=0) \n",
        "    X = np.array([np.array(mfcc)])\n",
        "    label = filename.split('/')[-1].split('_')[1]\n",
        "    pred = model.predict(X)\n",
        "    pred = np.round(pred,decimals=1)\n",
        "    pred = label_binarizer.inverse_transform(pred)\n",
        "    print(\"Actual Label: \",label)\n",
        "    print(\"Predicted Label: \",pred[0])\n",
        "  else:\n",
        "    print(\"Incompatible Audio\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4p8vlmfmLl1o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "793f5daf-ca5b-4993-8a9a-2bf2b656adef"
      },
      "source": [
        "testSample(files[300],model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Jakobovski-free-spoken-digit-dataset-e9e1155/recordings/0_nicolas_21.wav\n",
            "Actual Label:  nicolas\n",
            "Predicted Label:  nicolas\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zt1_oPczLmwr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkH6y0MZLm1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58ffbe49-f6f2-493e-8a54-9967f6beae70"
      },
      "source": [
        "# APPENDIX \n",
        "# code for loading the entire data into memory as numpy\n",
        "random.shuffle(files)\n",
        "X, y = [], []\n",
        "checkpoint = 0\n",
        "for i in range(len(files)):\n",
        "    wav = files[i]\n",
        "    wave, sr = librosa.load(wav, mono=True)\n",
        "    mfcc = librosa.feature.mfcc(wave, sr)\n",
        "    if(len(mfcc[0]) < 80 ):\n",
        "      mfcc = np.pad(mfcc, ((0,0), (0, max_length-len(mfcc[0]))), mode='constant', constant_values=0) \n",
        "      X.append(np.array(mfcc))\n",
        "      label = wav.split('/')[-1].split('_')[1]\n",
        "      y.append(label)\n",
        "      checkpoint+=1\n",
        "    if(checkpoint%100 ==0):\n",
        "      print(\"Current Data count Processed: \",checkpoint)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Current Data count Processed:  100\n",
            "Current Data count Processed:  200\n",
            "Current Data count Processed:  300\n",
            "Current Data count Processed:  400\n",
            "Current Data count Processed:  500\n",
            "Current Data count Processed:  600\n",
            "Current Data count Processed:  700\n",
            "Current Data count Processed:  800\n",
            "Current Data count Processed:  900\n",
            "Current Data count Processed:  1000\n",
            "Current Data count Processed:  1100\n",
            "Current Data count Processed:  1200\n",
            "Current Data count Processed:  1300\n",
            "Current Data count Processed:  1400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnOqPSeMLm5b"
      },
      "source": [
        "X = np.array(X)\n",
        "y = one_hot_encode(y)\n",
        "\n",
        "# Splitting the dataset into train and validation set \n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfU7Q0OZLm9N"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qH8aVoLaLnBF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ejh55kNXEvwJ"
      },
      "source": [
        "# CODE FOR DIGIT RECOGNITION USING CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FyO1ooOD8j05",
        "outputId": "3363ac75-4ace-4661-af06-1d9c700b2e49"
      },
      "source": [
        "!git clone https://github.com/Jakobovski/free-spoken-digit-dataset.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'free-spoken-digit-dataset'...\n",
            "remote: Enumerating objects: 4182, done.\u001b[K\n",
            "remote: Counting objects: 100% (510/510), done.\u001b[K\n",
            "remote: Compressing objects: 100% (510/510), done.\u001b[K\n",
            "remote: Total 4182 (delta 2), reused 502 (delta 0), pack-reused 3672\u001b[K\n",
            "Receiving objects: 100% (4182/4182), 30.44 MiB | 9.50 MiB/s, done.\n",
            "Resolving deltas: 100% (79/79), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMfVvCqNLdGw"
      },
      "source": [
        "pth = '/content/free-spoken-digit-dataset/recordings/*'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tw5TQhgZ-KpK",
        "outputId": "ed7d5702-f812-48c2-90d9-5b9fdd0fcc95"
      },
      "source": [
        "files = glob.glob(pth + \".wav\")\n",
        "len(files)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pt8GxM7z-KtP",
        "outputId": "6724a313-5a52-400e-95c0-4cce012f268d"
      },
      "source": [
        "X_train, X_val = train_test_split(files, test_size=0.2, random_state=7)\n",
        "\n",
        "print('# Training examples: {}'.format(len(X_train)))\n",
        "print('# Validation examples: {}'.format(len(X_val)))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# Training examples: 2400\n",
            "# Validation examples: 600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtBbyuaV-Kxi",
        "outputId": "7733edc4-271f-4203-c66c-0cf3f1c55e6e"
      },
      "source": [
        "labels = []\n",
        "for i in range(len(X_train)):\n",
        "    label = X_train[i].split('/')[-1].split('_')[1]\n",
        "    if label not in labels:\n",
        "        labels.append(label)\n",
        "print(labels)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['yweweler', 'george', 'lucas', 'theo', 'jackson', 'nicolas']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "is5ySHwc-K0-"
      },
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byVr7PRL-nZW"
      },
      "source": [
        "label_binarizer = LabelBinarizer()\n",
        "label_binarizer.fit(list(set(labels)))\n",
        "\n",
        "def one_hot_encode(x): return label_binarizer.transform(x)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oewYap9h-nZj"
      },
      "source": [
        "n_features = 20\n",
        "max_length = 80\n",
        "n_classes = len(labels)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCsH-RpN-6l6",
        "outputId": "05256773-70a3-4d00-c1b3-d49a3bc02b23"
      },
      "source": [
        "n_classes"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HN4R7pUq-nZk"
      },
      "source": [
        "def generator(number):\n",
        "    i=0\n",
        "    while i< number:\n",
        "        i = i+1\n",
        "        if i%2==0:\n",
        "            yield i"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcB8ja9r-nZk"
      },
      "source": [
        "datagen = generator(10)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CzN1NLJR-nZk",
        "outputId": "145320d4-419a-4f14-d03d-0855a7cddce8"
      },
      "source": [
        "next(datagen)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLNX_uNw-nZm"
      },
      "source": [
        "def batch_generator(data, batch_size=16):\n",
        "    while 1:\n",
        "        random.shuffle(data)\n",
        "        X, y = [], []\n",
        "        for i in range(batch_size):\n",
        "            wav = data[i]\n",
        "            wave, sr = librosa.load(wav, mono=True)\n",
        "            label = wav.split('/')[-1].split('_')[1]\n",
        "            y.append(label)\n",
        "            mfcc = librosa.feature.mfcc(wave, sr)\n",
        "            mfcc = np.pad(mfcc, ((0,0), (0, max_length-len(mfcc[0]))), mode='constant', constant_values=0) \n",
        "            X.append(np.array(mfcc))\n",
        "        yield np.array(X), np.array(one_hot_encode(y))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StifX7lf-nZm"
      },
      "source": [
        "train_datagen = batch_generator(X_train, batch_size=32)\n",
        "val_datagen = batch_generator(X_val, batch_size = 4)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdCV99r--nZm",
        "outputId": "fa22d4ff-5b9b-48c2-d023-f836ebed9d81"
      },
      "source": [
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import LSTM, Embedding, Input, Dense, BatchNormalization, Conv2D, MaxPooling2D, Dropout, Flatten, TimeDistributed\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "from IPython import display\n",
        "\n",
        "#Model DEFN\n",
        "input_shape = (n_features, max_length,1)\n",
        "model = Sequential([\n",
        "    layers.Input(shape=input_shape),\n",
        "    preprocessing.Resizing(32, 32), \n",
        "    # norm_layer,\n",
        "    layers.Conv2D(32, 3, activation='relu'),\n",
        "    layers.Conv2D(64, 3, activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Dropout(0.25),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(n_classes, activation='softmax')\n",
        "    ])\n",
        "model.summary()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "resizing_5 (Resizing)        (None, 32, 32, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 30, 30, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 28, 28, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 12544)             0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 128)               1605760   \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 6)                 774       \n",
            "=================================================================\n",
            "Total params: 1,625,350\n",
            "Trainable params: 1,625,350\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAk9fkUs-nZn"
      },
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-ThgfL8-nZn",
        "outputId": "67c650ae-903b-4a08-df61-ae38f19660bf"
      },
      "source": [
        "histroy = model.fit(\n",
        "            train_datagen, \n",
        "            steps_per_epoch=10,\n",
        "            epochs=3,\n",
        "            validation_data=val_datagen,\n",
        "            validation_steps=5,\n",
        "            validation_freq=1,\n",
        "            verbose=1)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "10/10 [==============================] - 42s 1s/step - loss: 7.0333 - accuracy: 0.2921 - val_loss: 0.4956 - val_accuracy: 0.8000\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 12s 1s/step - loss: 1.2473 - accuracy: 0.5289 - val_loss: 0.8708 - val_accuracy: 0.7000\n",
            "Epoch 3/3\n",
            "10/10 [==============================] - 12s 1s/step - loss: 0.9232 - accuracy: 0.6724 - val_loss: 0.3255 - val_accuracy: 0.9500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f18d52dba50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYWfo9AQGe39",
        "outputId": "7bb4cbc1-fc23-469a-9fd7-30279043096f"
      },
      "source": [
        "testSample(files[300],model)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/free-spoken-digit-dataset/recordings/8_nicolas_0.wav\n",
            "Actual Label:  nicolas\n",
            "Predicted Label:  nicolas\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-s02oY7h_rnt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhEPPIs9GoHK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pl04ql-6GoEe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bjc-lqToGo1Z"
      },
      "source": [
        "# Explorations here(Don't mind)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ph51AaCE_rrS"
      },
      "source": [
        "import csv\n",
        "import io\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import LSTM, Embedding, Input, Dense, BatchNormalization, Conv2D, MaxPooling2D, Dropout, Flatten, TimeDistributed\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import tensorflow_io as tfio\n",
        "import matplotlib.pyplot as plt\n",
        "maxData = 30\n",
        "block_length = 0.050#->500ms\n",
        "voice_max_length = int(10/block_length)#->2s\n",
        "print(\"voice_max_length:\", voice_max_length)\n",
        "def audioToTensor(filepath):\n",
        "    audio_binary = tf.io.read_file(filepath)\n",
        "    audio, audioSR = tf.audio.decode_wav(audio_binary)\n",
        "    audioSR = tf.get_static_value(audioSR)\n",
        "    audio = tf.squeeze(audio, axis=-1)\n",
        "    audio_length = int(audioSR * block_length)#20-> 50ms 40 -> 25ms\n",
        "    frame_step = int(audioSR * 0.008)# 128 when rate is 1600 -> 8ms\n",
        "    audio_clean = tf.constant([], tf.float32)\n",
        "    audio_length_clean = audioSR//20#50ms\n",
        "    for i in range(0, len(audio), audio_length_clean):\n",
        "        audio_slice = audio[i:i+audio_length_clean]\n",
        "        position = tfio.experimental.audio.trim(audio_slice, axis=0, epsilon=0.065)\n",
        "        start, stop=position[0], position[1]\n",
        "        if stop-start<5:\n",
        "            continue\n",
        "        audio_slice = audio_slice[start:stop]\n",
        "        audio_clean = tf.concat([audio_clean, audio_slice], 0)\n",
        "if len(audio_clean)<audio_length*voice_max_length:\n",
        "        audio = tf.concat([np.zeros([audio_length*voice_max_length-len(audio)]), audio], 0)\n",
        "    else:\n",
        "        audio = audio[-(audio_length*voice_max_length):]\n",
        "spectrogram = tf.signal.stft(audio, frame_length=1024, frame_step=frame_step)\n",
        "    spectrogram = (tf.math.log(tf.abs(tf.math.real(spectrogram)))/tf.math.log(tf.constant(10, dtype=tf.float32))*20)-60\n",
        "    spectrogram = tf.where(tf.math.is_nan(spectrogram), tf.zeros_like(spectrogram), spectrogram)\n",
        "    spectrogram = tf.where(tf.math.is_inf(spectrogram), tf.zeros_like(spectrogram), spectrogram)\n",
        "    voice_length, voice = 0, []\n",
        "    nb_part = len(audio)//audio_length\n",
        "    part_length = len(spectrogram)//nb_part\n",
        "    partsCount = len(range(0, len(spectrogram)-part_length, int(part_length/2)))\n",
        "    parts = np.zeros((partsCount, part_length, 513))\n",
        "    for i, p in enumerate(range(0, len(spectrogram)-part_length, int(part_length/2))):\n",
        "        part = spectrogram[p:p+part_length]\n",
        "        parts[i] = part\n",
        "    return parts\n",
        "testParts = audioToTensor('clips/common_voice_en_699711.wav')\n",
        "print(testParts.shape)\n",
        "def loadDataFromFile(filepath):\n",
        "    dataVoice, dataString = [], []\n",
        "    string_max_lenght = 0\n",
        "    with open(filepath) as tsvfile:\n",
        "      reader = csv.reader(tsvfile, delimiter='\\t')\n",
        "      next(reader)#skip header\n",
        "      for row in reader:\n",
        "        if len(dataString)>maxData:\n",
        "            break\n",
        "        sentence = row[2].replace(\".\", \"\")\n",
        "        wordList = (\"start \" + sentence + \" end\").split(\" \")\n",
        "        sentence = row[2].replace(\".\", \"\")\n",
        "        if(len(wordList)<5):\n",
        "            continue\n",
        "        print(row[1], row[2], wordList)\n",
        "        string_max_lenght = max(len(wordList), string_max_lenght)\n",
        "        dataString.append(wordList)\n",
        "        dataVoice.append(row[1].replace(\".mp3\", '.wav'))\n",
        "    return dataVoice, dataString, string_max_lenght\n",
        "dataVoice, dataString, string_max_lenght = loadDataFromFile('train.tsv')\n",
        "print(\"voice_max_length: \", voice_max_length)\n",
        "print(\"string_max_lenght: \", string_max_lenght)\n",
        "tokenizer = Tokenizer(num_words=2000, lower=True, oov_token=\"<rare>\")\n",
        "tokenizer.fit_on_texts(dataString)\n",
        "with io.open('tokenizer.txt', 'w', encoding='utf-8') as f:\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        f.write(word + \":\" + str(index) + \"\\n\")\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print('Vocabulary Size: %d' % vocab_size)\n",
        "def prepareData(dataString, dataVoice):\n",
        "    X_voice, X_string, Y_string = list(), list(), list()\n",
        "    for i, seq in enumerate(dataString):\n",
        "        voice =  dataVoice[i]\n",
        "        seq = tokenizer.texts_to_sequences([seq])[0]\n",
        "        for j in range(1, len(seq)):\n",
        "            in_seq, out_seq = seq[:j], seq[:j+1]\n",
        "            in_seq = pad_sequences([in_seq], maxlen=string_max_lenght-1)[0]\n",
        "            out_seq = pad_sequences([out_seq], maxlen=string_max_lenght-1)[0]\n",
        "            out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
        "            X_voice.append(voice)\n",
        "            X_string.append(in_seq)\n",
        "            Y_string.append(out_seq)\n",
        "    return X_voice, X_string, Y_string\n",
        "X_voice, X_string, Y_string = prepareData(dataString, dataVoice)\n",
        "print(\"len(X_voice): \", len(X_voice))\n",
        "class MySequence(tf.keras.utils.Sequence):\n",
        "    def __init__(self, x_voice, x_string, y_string, batch_size):\n",
        "        self.x_voice, self.x_string, self.y_string = x_voice, x_string, y_string\n",
        "        self.batch_size = batch_size\n",
        "    def __len__(self):\n",
        "        return int(len(self.x_voice) / self.batch_size)\n",
        "    def __getitem__(self, idx):\n",
        "        batch_x_string = self.x_string[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        batch_y_string = self.y_string[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        batch_x_voice = []\n",
        "        for i in range(0, batch_size):\n",
        "            voice = audioToTensor('clips/' + self.x_voice[idx * self.batch_size + i])\n",
        "            batch_x_voice.append(voice)\n",
        "        return [np.array(batch_x_voice), np.array(batch_x_string)], np.array(batch_y_string)\n",
        "def word_for_id(integer, tokenizer):\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == integer:\n",
        "            return word\n",
        "    return None\n",
        "latent_dim=64\n",
        "encoder_inputs = Input(shape=(testParts.shape[0], None, None, 1))\n",
        "preprocessing = TimeDistributed(preprocessing.Resizing(6, 129))(encoder_inputs)\n",
        "normalization = TimeDistributed(BatchNormalization())(preprocessing)\n",
        "conv2d = TimeDistributed(Conv2D(34, 3, activation='relu'))(normalization)\n",
        "conv2d = TimeDistributed(Conv2D(64, 3, activation='relu'))(conv2d)\n",
        "maxpool = TimeDistributed(MaxPooling2D())(conv2d)\n",
        "dropout = TimeDistributed(Dropout(0.25))(maxpool)\n",
        "flatten = TimeDistributed(Flatten())(dropout)\n",
        "encoder_lstm = LSTM(units=latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(flatten)\n",
        "encoder_states = [state_h, state_c]\n",
        "decoder_inputs = Input(shape=(string_max_lenght-1))\n",
        "dec_emb_layer = Embedding(vocab_size, latent_dim)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "decoder_lstm = LSTM(units=latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=encoder_states)\n",
        "decoder_dense = Dense(vocab_size, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.summary(line_length=200)\n",
        "tf.keras.utils.plot_model(model, to_file='model_sentence.png', show_shapes=True)\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n",
        "batch_size = 32\n",
        "epochs = 30\n",
        "model.fit(MySequence(X_voice, X_string, Y_string, batch_size), epochs=epochs, steps_per_epoch=len(X_string)//batch_size)\n",
        "model.save_weights('model_sentence.h5')\n",
        "model.save(\"model_sentence\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKZgZIDJ_ruT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}