{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab-9(Speech).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iam-pattan/DL-lab/blob/main/Lab_9(Speech).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sb_ulBynLySx"
      },
      "source": [
        "https://github.com/PacktPublishing/Python-Deep-Learning-Cookbook/blob/master/Chapter09/Chapter%209%20-%20Identifying%20speakers%20with%20voice%20recognition.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQ2xWNToKHya"
      },
      "source": [
        "import glob\n",
        "import numpy as np\n",
        "import random\n",
        "import librosa\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnwFPSOOKvH7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8652d839-74ed-4e3e-e2bd-8f0919931ef8"
      },
      "source": [
        "# !wget https://zenodo.org/record/1342401/files/Jakobovski/free-spoken-digit-dataset-v1.0.8.zip\n",
        "# !unzip free-spoken-digit-dataset-v1.0.8.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-30 10:05:17--  https://zenodo.org/record/1342401/files/Jakobovski/free-spoken-digit-dataset-v1.0.8.zip\n",
            "Resolving zenodo.org (zenodo.org)... 137.138.76.77\n",
            "Connecting to zenodo.org (zenodo.org)|137.138.76.77|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7273063 (6.9M) [application/octet-stream]\n",
            "Saving to: ‘free-spoken-digit-dataset-v1.0.8.zip.3’\n",
            "\n",
            "free-spoken-digit-d 100%[===================>]   6.94M  2.83MB/s    in 2.5s    \n",
            "\n",
            "2021-04-30 10:05:22 (2.83 MB/s) - ‘free-spoken-digit-dataset-v1.0.8.zip.3’ saved [7273063/7273063]\n",
            "\n",
            "Archive:  free-spoken-digit-dataset-v1.0.8.zip\n",
            "e9e1155aba3a0c632823b813aa74918807644509\n",
            "replace Jakobovski-free-spoken-digit-dataset-e9e1155/.gitignore? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUpRMJ6uKvO4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7075eed0-fed5-488d-bff6-5259c8b0d1ea"
      },
      "source": [
        "SEED = 123\n",
        "datapath = \"/content/Jakobovski-free-spoken-digit-dataset-e9e1155/recordings/\"\n",
        "'/content/Jakobovski-free-spoken-digit-dataset-e9e1155'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/Jakobovski-free-spoken-digit-dataset-e9e1155'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FoZ3YBu9KvSY",
        "outputId": "9fcbd640-e87f-4201-a34d-7b334c0b5a74"
      },
      "source": [
        "files = glob.glob(datapath+\"*.wav\")\n",
        "len(files)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1500"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fb5565IKvWq",
        "outputId": "feed8b2e-9105-4b9b-c32e-0ae9ef4de735"
      },
      "source": [
        "X_train, X_val = train_test_split(files, test_size=0.2, random_state=SEED)\n",
        "\n",
        "print('# Training examples: {}'.format(len(X_train)))\n",
        "print('# Validation examples: {}'.format(len(X_val)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# Training examples: 1200\n",
            "# Validation examples: 300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fmknQz_Kvbf",
        "outputId": "7db09b84-4cb0-4822-d487-80fba7fe6854"
      },
      "source": [
        "labels = []\n",
        "for i in range(len(X_train)):\n",
        "    label = X_train[i].split('/')[-1].split('_')[1]\n",
        "    if label not in labels:\n",
        "        labels.append(label)\n",
        "print(labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['nicolas', 'theo', 'jackson']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IClV0nlzKvgV"
      },
      "source": [
        "label_binarizer = LabelBinarizer()\n",
        "label_binarizer.fit(list(set(labels)))\n",
        "\n",
        "def one_hot_encode(x): return label_binarizer.transform(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opKpAg20Kvjo"
      },
      "source": [
        "n_features = 20\n",
        "max_length = 80\n",
        "n_classes = len(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygFVfgvpLID0"
      },
      "source": [
        "def generator(number):\n",
        "    i=0\n",
        "    while i< number:\n",
        "        i = i+1\n",
        "        if i%2==0:\n",
        "            yield i"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPg1Cd3jNAuS"
      },
      "source": [
        "datagen = generator(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-ehcku8QnFs",
        "outputId": "c9ab5bce-b81b-4e00-cd15-c797d58bdde4"
      },
      "source": [
        "next(datagen)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6V5XEt2LIHe"
      },
      "source": [
        "def batch_generator(data, batch_size=16):\n",
        "    while 1:\n",
        "        random.shuffle(data)\n",
        "        X, y = [], []\n",
        "        for i in range(batch_size):\n",
        "            wav = data[i]\n",
        "            wave, sr = librosa.load(wav, mono=True)\n",
        "            label = wav.split('/')[-1].split('_')[1]\n",
        "            y.append(label)\n",
        "            mfcc = librosa.feature.mfcc(wave, sr)\n",
        "            mfcc = np.pad(mfcc, ((0,0), (0, max_length-len(mfcc[0]))), mode='constant', constant_values=0) \n",
        "            X.append(np.array(mfcc))\n",
        "        yield np.array(X), np.array(one_hot_encode(y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFfBZe9-LILu"
      },
      "source": [
        "train_datagen = batch_generator(X_train, batch_size=32)\n",
        "val_datagen = batch_generator(X_val, batch_size = 4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_nGjOfRLIPh"
      },
      "source": [
        "#Model DEFN\n",
        "input_shape = (n_features, max_length)\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.LSTM(256, return_sequences=True, input_shape=input_shape,\n",
        "dropout=0.5))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "model.add(tf.keras.layers.Dense(n_classes, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5plFssvKvm5"
      },
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGHw5LQtLc2o"
      },
      "source": [
        "callbacks = [tf.keras.callbacks.ModelCheckpoint('SPEAKER_best_model_.hdf5', save_best_only=True),\n",
        "            tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=2)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-i391u1Lc60"
      },
      "source": [
        "# help(model.fit)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kAG_59KLc-9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5fff1967-3561-4736-c8c1-39bcbc2eaceb"
      },
      "source": [
        "history = model.fit(\n",
        "    train_datagen, \n",
        "    steps_per_epoch=10,\n",
        "    epochs=3,\n",
        "    validation_data=val_datagen,\n",
        "    validation_steps=5,\n",
        "    validation_freq=1,\n",
        "    verbose=1\n",
        "    # callbacks = callbacks\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "10/10 [==============================] - 12s 1s/step - loss: 1.0271 - accuracy: 0.4861 - val_loss: 0.4402 - val_accuracy: 0.8000\n",
            "Epoch 2/3\n",
            "10/10 [==============================] - 9s 1s/step - loss: 0.5995 - accuracy: 0.7050 - val_loss: 0.4657 - val_accuracy: 0.8000\n",
            "Epoch 3/3\n",
            " 4/10 [===========>..................] - ETA: 5s - loss: 0.5102 - accuracy: 0.7715"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-88-dc534c2f3764>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;31m# callbacks = callbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m:  ValueError: index can't contain negative values\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/script_ops.py\", line 249, in __call__\n    ret = func(*args)\n\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\", line 620, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\", line 891, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/data_adapter.py\", line 807, in wrapped_generator\n    for data in generator_fn():\n\n  File \"<ipython-input-82-3a2dcccec367>\", line 11, in batch_generator\n    mfcc = np.pad(mfcc, ((0,0), (0, max_length-len(mfcc[0]))), mode='constant', constant_values=0)\n\n  File \"<__array_function__ internals>\", line 6, in pad\n\n  File \"/usr/local/lib/python3.7/dist-packages/numpy/lib/arraypad.py\", line 746, in pad\n    pad_width = _as_pairs(pad_width, array.ndim, as_index=True)\n\n  File \"/usr/local/lib/python3.7/dist-packages/numpy/lib/arraypad.py\", line 517, in _as_pairs\n    raise ValueError(\"index can't contain negative values\")\n\nValueError: index can't contain negative values\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_13998]\n\nFunction call stack:\ntrain_function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DsfluSpLdDu"
      },
      "source": [
        "def testSample(filename,model):\n",
        "  # Read the WAV file and transform it into mfcc\n",
        "  print(filename)\n",
        "  max_length = 80\n",
        "  wave, sr = librosa.load(filename, mono=True)\n",
        "  mfcc = librosa.feature.mfcc(wave, sr)\n",
        "  if(len(mfcc[0]) < 60 ):\n",
        "    mfcc = np.pad(mfcc, ((0,0), (0, max_length-len(mfcc[0]))), mode='constant', constant_values=0) \n",
        "    X = np.array([np.array(mfcc)])\n",
        "    label = filename.split('/')[-1].split('_')[1]\n",
        "    pred = model.predict(X)\n",
        "    pred = np.round(pred,decimals=1)\n",
        "    pred = label_binarizer.inverse_transform(pred)\n",
        "    print(\"Actual Label: \",label)\n",
        "    print(\"Predicted Label: \",pred[0])\n",
        "  else:\n",
        "    print(\"Incompatible Audio\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4p8vlmfmLl1o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "793f5daf-ca5b-4993-8a9a-2bf2b656adef"
      },
      "source": [
        "testSample(files[300],model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Jakobovski-free-spoken-digit-dataset-e9e1155/recordings/0_nicolas_21.wav\n",
            "Actual Label:  nicolas\n",
            "Predicted Label:  nicolas\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zt1_oPczLmwr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkH6y0MZLm1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58ffbe49-f6f2-493e-8a54-9967f6beae70"
      },
      "source": [
        "# APPENDIX \n",
        "# code for loading the entire data into memory as numpy\n",
        "random.shuffle(files)\n",
        "X, y = [], []\n",
        "checkpoint = 0\n",
        "for i in range(len(files)):\n",
        "    wav = files[i]\n",
        "    wave, sr = librosa.load(wav, mono=True)\n",
        "    mfcc = librosa.feature.mfcc(wave, sr)\n",
        "    if(len(mfcc[0]) < 80 ):\n",
        "      mfcc = np.pad(mfcc, ((0,0), (0, max_length-len(mfcc[0]))), mode='constant', constant_values=0) \n",
        "      X.append(np.array(mfcc))\n",
        "      label = wav.split('/')[-1].split('_')[1]\n",
        "      y.append(label)\n",
        "      checkpoint+=1\n",
        "    if(checkpoint%100 ==0):\n",
        "      print(\"Current Data count Processed: \",checkpoint)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Current Data count Processed:  100\n",
            "Current Data count Processed:  200\n",
            "Current Data count Processed:  300\n",
            "Current Data count Processed:  400\n",
            "Current Data count Processed:  500\n",
            "Current Data count Processed:  600\n",
            "Current Data count Processed:  700\n",
            "Current Data count Processed:  800\n",
            "Current Data count Processed:  900\n",
            "Current Data count Processed:  1000\n",
            "Current Data count Processed:  1100\n",
            "Current Data count Processed:  1200\n",
            "Current Data count Processed:  1300\n",
            "Current Data count Processed:  1400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnOqPSeMLm5b"
      },
      "source": [
        "X = np.array(X)\n",
        "y = one_hot_encode(y)\n",
        "\n",
        "# Splitting the dataset into train and validation set \n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfU7Q0OZLm9N"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qH8aVoLaLnBF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMfVvCqNLdGw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}