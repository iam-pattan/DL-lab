{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab_5.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ADLgRuA0lFA-"
      ],
      "mount_file_id": "1X4HfMOJCdNs2eub8Ueu5Lt1U3XEpzWhC",
      "authorship_tag": "ABX9TyOefS99gmBhR3rD9fO94UPl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iam-pattan/DL-lab/blob/main/Lab_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPky-ZYRopjG"
      },
      "source": [
        "https://towardsdatascience.com/a-comprehensive-hands-on-guide-to-transfer-learning-with-real-world-applications-in-deep-learning-212bf3b2f27a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADLgRuA0lFA-"
      },
      "source": [
        "## Code-1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLsprh_tj2VM"
      },
      "source": [
        "https://analyticsindiamag.com/transfer-learning-for-multi-class-image-classification-using-deep-convolutional-neural-network/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HY7uH2R-3OxJ"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import seaborn as sns\n",
        "import itertools\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras import Sequential\n",
        "from keras.layers import Flatten, Dense, Dropout, BatchNormalization, Activation\n",
        "from keras.applications import VGG19 #For Transfer Learning\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import SGD,Adam\n",
        "\n",
        "from keras.callbacks import ReduceLROnPlateau"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljwXKbus4Iev",
        "outputId": "effdb025-cf16-48a1-cf7a-380df59796ab"
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "\n",
        "#Downloading the CIFAR dataset\n",
        "(x_train,y_train),(x_test,y_test)=cifar10.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 6s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaXRXrqEdgf4"
      },
      "source": [
        "#defining training and test sets\n",
        "x_train,x_val,y_train,y_val=train_test_split(x_train,y_train,test_size=.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3WbkTLI4Iss",
        "outputId": "d206ec04-d5a0-4e09-ebd8-6fb19ea2c2f4"
      },
      "source": [
        "x_train.shape, y_train.shape, x_test.shape, y_test.shape, x_val.shape, y_val.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((35000, 32, 32, 3),\n",
              " (35000, 1),\n",
              " (10000, 32, 32, 3),\n",
              " (10000, 1),\n",
              " (15000, 32, 32, 3),\n",
              " (15000, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDrDmRKG4IzG"
      },
      "source": [
        "#One Hot Encoding\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "y_train=to_categorical(y_train)\n",
        "y_val=to_categorical(y_val)\n",
        "y_test=to_categorical(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHhqZFwL4I5S"
      },
      "source": [
        "#Image Data Augmentation\n",
        "train_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True, zoom_range=.1)\n",
        "\n",
        "val_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True, zoom_range=.1)\n",
        "\n",
        "test_generator = ImageDataGenerator(rotation_range=2, horizontal_flip= True, zoom_range=.1)\n",
        "\n",
        "#Fitting the augmentation defined above to the data\n",
        "train_generator.fit(x_train)\n",
        "val_generator.fit(x_val)\n",
        "test_generator.fit(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cT1f4-I05Jh2"
      },
      "source": [
        "#Learning Rate Annealer\n",
        "lrr= ReduceLROnPlateau(monitor='val_acc', factor=.01, patience=3, min_lr=1e-5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VihUKPR-5Jv2",
        "outputId": "bd09d82e-6301-48fb-c277-9907a49a8751"
      },
      "source": [
        "#Defining the VGG Convolutional Neural Net\n",
        "base_model = VGG19(include_top = False, weights = 'imagenet', input_shape = (32,32,3), classes = y_train.shape[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80142336/80134624 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUqqZGsh5J9D"
      },
      "source": [
        "model= Sequential()\n",
        "model.add(base_model) \n",
        "model.add(Flatten())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWbXWba75KJD",
        "outputId": "3f2ea3ac-0ac6-4240-c219-258086ef6f6c"
      },
      "source": [
        "#Model summary\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg19 (Functional)           (None, 1, 1, 512)         20024384  \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 512)               0         \n",
            "=================================================================\n",
            "Total params: 20,024,384\n",
            "Trainable params: 20,024,384\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nUdZU4T5KTC",
        "outputId": "56156b43-7c40-4730-e6c2-5f4a0d60a01f"
      },
      "source": [
        "#Adding the Dense layers along with activation and batch normalization\n",
        "model.add(Dense(1024,activation=('relu'),input_dim=512))\n",
        "model.add(Dense(512,activation=('relu'))) \n",
        "model.add(Dense(256,activation=('relu'))) \n",
        "model.add(Dense(128,activation=('relu')))\n",
        "model.add(Dropout(.3))\n",
        "\n",
        "#model.add(Dropout(.2))\n",
        "model.add(Dense(10,activation=('softmax'))) \n",
        "\n",
        "#Checking the final model summary\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg19 (Functional)           (None, 1, 1, 512)         20024384  \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1024)              525312    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 21,240,010\n",
            "Trainable params: 21,240,010\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1dfn21X5Kc0"
      },
      "source": [
        "#Initializing the hyperparameters\n",
        "batch_size= 100\n",
        "epochs=5\n",
        "learn_rate=.001\n",
        "sgd=SGD(lr=learn_rate,momentum=.9,nesterov=False)\n",
        "adam=Adam(lr=learn_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "model.compile(optimizer=sgd,loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rJV3n7Z5Kma"
      },
      "source": [
        "#Training the model\n",
        "model.fit_generator(train_generator.flow(x_train, y_train, batch_size= batch_size), epochs = epochs, steps_per_epoch = x_train.shape[0]//batch_size, validation_data = val_generator.flow(x_val, y_val, batch_size = batch_size), validation_steps=250, callbacks=[lrr], verbose = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YYzhIwU6Zs5"
      },
      "source": [
        "#Plotting the training and validation loss and accuracy\n",
        "f,ax=plt.subplots(2,1) \n",
        "\n",
        "#Loss\n",
        "ax[0].plot(model.history.history['loss'],color='b',label='Training Loss')\n",
        "ax[0].plot(model.history.history['val_loss'],color='r',label='Validation Loss')\n",
        "\n",
        "#Accuracy\n",
        "ax[1].plot(model.history.history['accuracy'],color='b',label='Training  Accuracy')\n",
        "ax[1].plot(model.history.history['val_accuracy'],color='r',label='Validation Accuracy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KK8NozG6Z1x"
      },
      "source": [
        "#Making prediction\n",
        "y_pred=model.predict_classes(x_test)\n",
        "y_true=np.argmax(y_test,axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YoJ70DFb6Z-s"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WAxtTkWlI8w"
      },
      "source": [
        "## Code-2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnsgNMaA6aHO"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras import Sequential\n",
        "import tensorflow_datasets as tfds\n",
        "from keras.layers import Flatten, Dense, Dropout, BatchNormalization, Activation\n",
        "from keras.applications import VGG19 #For Transfer Learning\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import SGD,Adam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJ3cXOoTW7oB",
        "outputId": "8f6c418a-45ad-44e0-9565-4228342f9a44"
      },
      "source": [
        "!wget 'https://github.com/krishnaik06/Deep-Learning-Car-Brand/raw/master/Datasets.zip'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-24 08:32:00--  https://github.com/krishnaik06/Deep-Learning-Car-Brand/raw/master/Datasets.zip\n",
            "Resolving github.com (github.com)... 140.82.121.4\n",
            "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/krishnaik06/Deep-Learning-Car-Brand/master/Datasets.zip [following]\n",
            "--2021-03-24 08:32:00--  https://raw.githubusercontent.com/krishnaik06/Deep-Learning-Car-Brand/master/Datasets.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1106994 (1.1M) [application/zip]\n",
            "Saving to: ‘Datasets.zip’\n",
            "\n",
            "\rDatasets.zip          0%[                    ]       0  --.-KB/s               \rDatasets.zip        100%[===================>]   1.06M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2021-03-24 08:32:00 (22.1 MB/s) - ‘Datasets.zip’ saved [1106994/1106994]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQ44iGWTXOuY"
      },
      "source": [
        "!unzip /content/Datasets.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVj9k7XH6aYV"
      },
      "source": [
        "#defining training and test sets\n",
        "train_pth = '/content/Datasets/Train/'\n",
        "test_pth = '/content/Datasets/Test/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJace4ocX_Be",
        "outputId": "a1997d4f-8126-4bb5-801c-c1d0b851c69b"
      },
      "source": [
        "from glob import glob\n",
        "train = glob(train_pth+'/*')\n",
        "len(train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 255
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SgD-p8EbLJwj",
        "outputId": "fdc0572a-bece-4887-d5df-b3942e6beb93"
      },
      "source": [
        "train_gen = ImageDataGenerator( rescale=1./255).flow_from_directory(train_pth, target_size=(224,224), classes=['lamborghini', 'audi', 'mercedes'])\n",
        "test_gen = ImageDataGenerator( rescale=1./255).flow_from_directory(test_pth, target_size=(224,224), classes=['lamborghini', 'audi', 'mercedes'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 64 images belonging to 3 classes.\n",
            "Found 58 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjXhb9KSakhx"
      },
      "source": [
        "from keras.applications import MobileNet\n",
        "\n",
        "mobnet = MobileNet()\n",
        "vgg = VGG19(weights='imagenet', include_top=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6n0NjnWOe6q"
      },
      "source": [
        "for layer in mobnet.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "for layer in vgg.layers:\n",
        "    layer.trainable = False  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLqeZQ2ym5_v"
      },
      "source": [
        "model = Sequential()\n",
        "for layers in mobnet.layers:\n",
        "  model.add(layers)\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(len(train), activation='softmax'))\n",
        "# model.summary()\n",
        "\n",
        "\n",
        "fc = Flatten()(vgg.output)\n",
        "final_layer = Dense(len(train), activation='softmax')(fc)\n",
        "model_vgg = Model(vgg.input, final_layer)\n",
        "model_vgg.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubIlZI3jiAww"
      },
      "source": [
        "import keras.optimizers as opt \n",
        "dir(opt)\n",
        "optim = opt.Adam()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hye5vESeri_o"
      },
      "source": [
        "optim1 = opt.Nadam()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUzTanY_lVCG"
      },
      "source": [
        "optim2 = tfa.optimizers.AdamW(0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPSipF1-oL9Z"
      },
      "source": [
        "# !pip install keras-adabound\n",
        "from keras_adabound import AdaBound\n",
        "\n",
        "optim3=AdaBound(lr=1e-3, final_lr=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsfHdm8kMU-U"
      },
      "source": [
        "model.compile(\n",
        "    optimizer = 'SGD',\n",
        "    loss = 'categorical_crossentropy',\n",
        "    metrics = ['accuracy']\n",
        ")\n",
        "\n",
        "model_vgg.compile(\n",
        "    optimizer = 'adam',\n",
        "    loss = 'categorical_crossentropy',\n",
        "    metrics = ['accuracy']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGFzhedgMaAT",
        "outputId": "d84425a8-0397-4cc7-e2cc-89af1bd5521e"
      },
      "source": [
        "  history = model.fit_generator(train_gen, epochs=50, validation_data = test_gen)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "2/2 [==============================] - 2s 701ms/step - loss: 1.0843 - accuracy: 0.5417 - val_loss: 1.0841 - val_accuracy: 0.6379\n",
            "Epoch 2/50\n",
            "2/2 [==============================] - 0s 217ms/step - loss: 1.0851 - accuracy: 0.5000 - val_loss: 1.0836 - val_accuracy: 0.6379\n",
            "Epoch 3/50\n",
            "2/2 [==============================] - 0s 219ms/step - loss: 1.0843 - accuracy: 0.5104 - val_loss: 1.0830 - val_accuracy: 0.6379\n",
            "Epoch 4/50\n",
            "2/2 [==============================] - 0s 216ms/step - loss: 1.0834 - accuracy: 0.5208 - val_loss: 1.0825 - val_accuracy: 0.6379\n",
            "Epoch 5/50\n",
            "2/2 [==============================] - 0s 222ms/step - loss: 1.0799 - accuracy: 0.5625 - val_loss: 1.0819 - val_accuracy: 0.6379\n",
            "Epoch 6/50\n",
            "2/2 [==============================] - 0s 225ms/step - loss: 1.0792 - accuracy: 0.5625 - val_loss: 1.0814 - val_accuracy: 0.6379\n",
            "Epoch 7/50\n",
            "2/2 [==============================] - 0s 221ms/step - loss: 1.0818 - accuracy: 0.5208 - val_loss: 1.0809 - val_accuracy: 0.6379\n",
            "Epoch 8/50\n",
            "2/2 [==============================] - 0s 212ms/step - loss: 1.0825 - accuracy: 0.5000 - val_loss: 1.0803 - val_accuracy: 0.6379\n",
            "Epoch 9/50\n",
            "2/2 [==============================] - 0s 215ms/step - loss: 1.0799 - accuracy: 0.5312 - val_loss: 1.0798 - val_accuracy: 0.6379\n",
            "Epoch 10/50\n",
            "2/2 [==============================] - 0s 212ms/step - loss: 1.0791 - accuracy: 0.5417 - val_loss: 1.0793 - val_accuracy: 0.6379\n",
            "Epoch 11/50\n",
            "2/2 [==============================] - 0s 215ms/step - loss: 1.0764 - accuracy: 0.5729 - val_loss: 1.0787 - val_accuracy: 0.6552\n",
            "Epoch 12/50\n",
            "2/2 [==============================] - 0s 218ms/step - loss: 1.0811 - accuracy: 0.5000 - val_loss: 1.0782 - val_accuracy: 0.6552\n",
            "Epoch 13/50\n",
            "2/2 [==============================] - 0s 222ms/step - loss: 1.0755 - accuracy: 0.5521 - val_loss: 1.0777 - val_accuracy: 0.6552\n",
            "Epoch 14/50\n",
            "2/2 [==============================] - 0s 221ms/step - loss: 1.0774 - accuracy: 0.5417 - val_loss: 1.0772 - val_accuracy: 0.6552\n",
            "Epoch 15/50\n",
            "2/2 [==============================] - 0s 214ms/step - loss: 1.0771 - accuracy: 0.5521 - val_loss: 1.0767 - val_accuracy: 0.6379\n",
            "Epoch 16/50\n",
            "2/2 [==============================] - 0s 215ms/step - loss: 1.0785 - accuracy: 0.4688 - val_loss: 1.0762 - val_accuracy: 0.6379\n",
            "Epoch 17/50\n",
            "2/2 [==============================] - 0s 219ms/step - loss: 1.0757 - accuracy: 0.5104 - val_loss: 1.0757 - val_accuracy: 0.6379\n",
            "Epoch 18/50\n",
            "2/2 [==============================] - 0s 216ms/step - loss: 1.0763 - accuracy: 0.5000 - val_loss: 1.0752 - val_accuracy: 0.6379\n",
            "Epoch 19/50\n",
            "2/2 [==============================] - 0s 217ms/step - loss: 1.0751 - accuracy: 0.5104 - val_loss: 1.0747 - val_accuracy: 0.6379\n",
            "Epoch 20/50\n",
            "2/2 [==============================] - 0s 221ms/step - loss: 1.0724 - accuracy: 0.5417 - val_loss: 1.0742 - val_accuracy: 0.6379\n",
            "Epoch 21/50\n",
            "2/2 [==============================] - 0s 218ms/step - loss: 1.0751 - accuracy: 0.5000 - val_loss: 1.0737 - val_accuracy: 0.6379\n",
            "Epoch 22/50\n",
            "2/2 [==============================] - 0s 215ms/step - loss: 1.0748 - accuracy: 0.5312 - val_loss: 1.0732 - val_accuracy: 0.6379\n",
            "Epoch 23/50\n",
            "2/2 [==============================] - 0s 217ms/step - loss: 1.0721 - accuracy: 0.5312 - val_loss: 1.0727 - val_accuracy: 0.6379\n",
            "Epoch 24/50\n",
            "2/2 [==============================] - 0s 213ms/step - loss: 1.0710 - accuracy: 0.5208 - val_loss: 1.0722 - val_accuracy: 0.6379\n",
            "Epoch 25/50\n",
            "2/2 [==============================] - 0s 216ms/step - loss: 1.0735 - accuracy: 0.5104 - val_loss: 1.0717 - val_accuracy: 0.6379\n",
            "Epoch 26/50\n",
            "2/2 [==============================] - 0s 217ms/step - loss: 1.0723 - accuracy: 0.5208 - val_loss: 1.0712 - val_accuracy: 0.6379\n",
            "Epoch 27/50\n",
            "2/2 [==============================] - 0s 212ms/step - loss: 1.0699 - accuracy: 0.5312 - val_loss: 1.0707 - val_accuracy: 0.6379\n",
            "Epoch 28/50\n",
            "2/2 [==============================] - 0s 218ms/step - loss: 1.0722 - accuracy: 0.4896 - val_loss: 1.0702 - val_accuracy: 0.6379\n",
            "Epoch 29/50\n",
            "2/2 [==============================] - 0s 218ms/step - loss: 1.0683 - accuracy: 0.5417 - val_loss: 1.0698 - val_accuracy: 0.6379\n",
            "Epoch 30/50\n",
            "2/2 [==============================] - 0s 229ms/step - loss: 1.0715 - accuracy: 0.5000 - val_loss: 1.0693 - val_accuracy: 0.6379\n",
            "Epoch 31/50\n",
            "2/2 [==============================] - 0s 222ms/step - loss: 1.0707 - accuracy: 0.5000 - val_loss: 1.0688 - val_accuracy: 0.6379\n",
            "Epoch 32/50\n",
            "2/2 [==============================] - 0s 218ms/step - loss: 1.0661 - accuracy: 0.5729 - val_loss: 1.0684 - val_accuracy: 0.6379\n",
            "Epoch 33/50\n",
            "2/2 [==============================] - 0s 219ms/step - loss: 1.0676 - accuracy: 0.5208 - val_loss: 1.0679 - val_accuracy: 0.6379\n",
            "Epoch 34/50\n",
            "2/2 [==============================] - 0s 227ms/step - loss: 1.0702 - accuracy: 0.5000 - val_loss: 1.0674 - val_accuracy: 0.6379\n",
            "Epoch 35/50\n",
            "2/2 [==============================] - 0s 221ms/step - loss: 1.0701 - accuracy: 0.5104 - val_loss: 1.0670 - val_accuracy: 0.6379\n",
            "Epoch 36/50\n",
            "2/2 [==============================] - 0s 220ms/step - loss: 1.0637 - accuracy: 0.5521 - val_loss: 1.0665 - val_accuracy: 0.6379\n",
            "Epoch 37/50\n",
            "2/2 [==============================] - 0s 219ms/step - loss: 1.0657 - accuracy: 0.5208 - val_loss: 1.0660 - val_accuracy: 0.6379\n",
            "Epoch 38/50\n",
            "2/2 [==============================] - 0s 219ms/step - loss: 1.0654 - accuracy: 0.5417 - val_loss: 1.0656 - val_accuracy: 0.6379\n",
            "Epoch 39/50\n",
            "2/2 [==============================] - 0s 214ms/step - loss: 1.0638 - accuracy: 0.5417 - val_loss: 1.0651 - val_accuracy: 0.6379\n",
            "Epoch 40/50\n",
            "2/2 [==============================] - 0s 216ms/step - loss: 1.0691 - accuracy: 0.4896 - val_loss: 1.0647 - val_accuracy: 0.6379\n",
            "Epoch 41/50\n",
            "2/2 [==============================] - 0s 224ms/step - loss: 1.0684 - accuracy: 0.5104 - val_loss: 1.0642 - val_accuracy: 0.6379\n",
            "Epoch 42/50\n",
            "2/2 [==============================] - 0s 212ms/step - loss: 1.0649 - accuracy: 0.5208 - val_loss: 1.0638 - val_accuracy: 0.6379\n",
            "Epoch 43/50\n",
            "2/2 [==============================] - 0s 220ms/step - loss: 1.0621 - accuracy: 0.5312 - val_loss: 1.0633 - val_accuracy: 0.6379\n",
            "Epoch 44/50\n",
            "2/2 [==============================] - 0s 215ms/step - loss: 1.0656 - accuracy: 0.4792 - val_loss: 1.0629 - val_accuracy: 0.6379\n",
            "Epoch 45/50\n",
            "2/2 [==============================] - 0s 211ms/step - loss: 1.0659 - accuracy: 0.5104 - val_loss: 1.0624 - val_accuracy: 0.6379\n",
            "Epoch 46/50\n",
            "2/2 [==============================] - 0s 220ms/step - loss: 1.0646 - accuracy: 0.5208 - val_loss: 1.0620 - val_accuracy: 0.6379\n",
            "Epoch 47/50\n",
            "2/2 [==============================] - 0s 229ms/step - loss: 1.0667 - accuracy: 0.5000 - val_loss: 1.0615 - val_accuracy: 0.6379\n",
            "Epoch 48/50\n",
            "2/2 [==============================] - 0s 224ms/step - loss: 1.0648 - accuracy: 0.5312 - val_loss: 1.0611 - val_accuracy: 0.6379\n",
            "Epoch 49/50\n",
            "2/2 [==============================] - 0s 229ms/step - loss: 1.0585 - accuracy: 0.5521 - val_loss: 1.0607 - val_accuracy: 0.6379\n",
            "Epoch 50/50\n",
            "2/2 [==============================] - 0s 217ms/step - loss: 1.0582 - accuracy: 0.5521 - val_loss: 1.0602 - val_accuracy: 0.6207\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMCJu6D7sl5m"
      },
      "source": [
        "-> Adam is giving train `77.08` and test `67.24` \n",
        "\n",
        "-> AdamW is giving train `71.8` and test `62.07`\n",
        "\n",
        "-> Nadam is giving train `67.7` and test `63.79`\n",
        "\n",
        "-> Adabound is giving train `63.5` and test `67.24`\n",
        "\n",
        "-> SGD is giving train `61.46` and test `62.07`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 945
        },
        "id": "qQZkERVlxmoL",
        "outputId": "b622fcd5-60cd-4663-8ce9-51d9b1dfbb62"
      },
      "source": [
        "history_vgg = model_vgg.fit_generator(train_gen, epochs=50, validation_data = test_gen)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "2/2 [==============================] - 3s 754ms/step - loss: 1.0989 - accuracy: 0.2917 - val_loss: 1.1156 - val_accuracy: 0.1552\n",
            "Epoch 2/50\n",
            "2/2 [==============================] - 1s 490ms/step - loss: 1.0960 - accuracy: 0.3125 - val_loss: 1.1155 - val_accuracy: 0.1552\n",
            "Epoch 3/50\n",
            "2/2 [==============================] - 1s 483ms/step - loss: 1.0963 - accuracy: 0.3125 - val_loss: 1.1153 - val_accuracy: 0.1552\n",
            "Epoch 4/50\n",
            "2/2 [==============================] - 1s 485ms/step - loss: 1.0968 - accuracy: 0.3229 - val_loss: 1.1151 - val_accuracy: 0.3276\n",
            "Epoch 5/50\n",
            "2/2 [==============================] - 1s 485ms/step - loss: 1.0966 - accuracy: 0.3854 - val_loss: 1.1149 - val_accuracy: 0.3276\n",
            "Epoch 6/50\n",
            "2/2 [==============================] - 1s 482ms/step - loss: 1.0927 - accuracy: 0.4062 - val_loss: 1.1149 - val_accuracy: 0.3276\n",
            "Epoch 7/50\n",
            "2/2 [==============================] - 1s 494ms/step - loss: 1.0942 - accuracy: 0.3958 - val_loss: 1.1147 - val_accuracy: 0.3276\n",
            "Epoch 8/50\n",
            "2/2 [==============================] - 1s 484ms/step - loss: 1.0976 - accuracy: 0.3854 - val_loss: 1.1144 - val_accuracy: 0.3276\n",
            "Epoch 9/50\n",
            "2/2 [==============================] - 1s 482ms/step - loss: 1.0935 - accuracy: 0.4062 - val_loss: 1.1143 - val_accuracy: 0.3276\n",
            "Epoch 10/50\n",
            "2/2 [==============================] - 1s 492ms/step - loss: 1.0919 - accuracy: 0.3958 - val_loss: 1.1143 - val_accuracy: 0.3276\n",
            "Epoch 11/50\n",
            "2/2 [==============================] - 1s 485ms/step - loss: 1.0940 - accuracy: 0.3750 - val_loss: 1.1143 - val_accuracy: 0.3276\n",
            "Epoch 12/50\n",
            "2/2 [==============================] - 1s 482ms/step - loss: 1.0947 - accuracy: 0.3958 - val_loss: 1.1142 - val_accuracy: 0.3276\n",
            "Epoch 13/50\n",
            "2/2 [==============================] - 1s 491ms/step - loss: 1.0908 - accuracy: 0.4062 - val_loss: 1.1142 - val_accuracy: 0.3276\n",
            "Epoch 14/50\n",
            "2/2 [==============================] - 1s 484ms/step - loss: 1.0938 - accuracy: 0.4062 - val_loss: 1.1141 - val_accuracy: 0.3276\n",
            "Epoch 15/50\n",
            "2/2 [==============================] - 1s 499ms/step - loss: 1.0949 - accuracy: 0.3958 - val_loss: 1.1140 - val_accuracy: 0.3276\n",
            "Epoch 16/50\n",
            "2/2 [==============================] - 1s 488ms/step - loss: 1.0924 - accuracy: 0.3958 - val_loss: 1.1140 - val_accuracy: 0.3276\n",
            "Epoch 17/50\n",
            "2/2 [==============================] - 1s 485ms/step - loss: 1.0937 - accuracy: 0.3854 - val_loss: 1.1140 - val_accuracy: 0.3276\n",
            "Epoch 18/50\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-362-39f81567b829>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory_vgg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_vgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1859\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1861\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1863\u001b[0m   def evaluate_generator(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1103\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1105\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1106\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    452\u001b[0m     \"\"\"\n\u001b[1;32m    453\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    294\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    314\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_supports_tf_logs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1020\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1084\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1085\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    508\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1069\u001b[0m     \"\"\"\n\u001b[1;32m   1070\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1071\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1035\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUD31hh1MaGR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8N0wepnwMaMD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bj5wQ1hbsaPz"
      },
      "source": [
        "tensorflow addons to try different losses, optimizers,,............................just trying stuff "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zl7cvcHln-eB",
        "outputId": "440db928-e455-4cf0-809f-c779474678a2"
      },
      "source": [
        "!pip install tensorflow_addons"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow_addons\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/e3/56d2fe76f0bb7c88ed9b2a6a557e25e83e252aec08f13de34369cd850a0b/tensorflow_addons-0.12.1-cp37-cp37m-manylinux2010_x86_64.whl (703kB)\n",
            "\r\u001b[K     |▌                               | 10kB 24.8MB/s eta 0:00:01\r\u001b[K     |█                               | 20kB 30.4MB/s eta 0:00:01\r\u001b[K     |█▍                              | 30kB 21.9MB/s eta 0:00:01\r\u001b[K     |█▉                              | 40kB 17.1MB/s eta 0:00:01\r\u001b[K     |██▎                             | 51kB 14.8MB/s eta 0:00:01\r\u001b[K     |██▉                             | 61kB 13.9MB/s eta 0:00:01\r\u001b[K     |███▎                            | 71kB 15.3MB/s eta 0:00:01\r\u001b[K     |███▊                            | 81kB 15.2MB/s eta 0:00:01\r\u001b[K     |████▏                           | 92kB 14.3MB/s eta 0:00:01\r\u001b[K     |████▋                           | 102kB 15.5MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 112kB 15.5MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 122kB 15.5MB/s eta 0:00:01\r\u001b[K     |██████                          | 133kB 15.5MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 143kB 15.5MB/s eta 0:00:01\r\u001b[K     |███████                         | 153kB 15.5MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 163kB 15.5MB/s eta 0:00:01\r\u001b[K     |████████                        | 174kB 15.5MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 184kB 15.5MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 194kB 15.5MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 204kB 15.5MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 215kB 15.5MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 225kB 15.5MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 235kB 15.5MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 245kB 15.5MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 256kB 15.5MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 266kB 15.5MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 276kB 15.5MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 286kB 15.5MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 296kB 15.5MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 307kB 15.5MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 317kB 15.5MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 327kB 15.5MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 337kB 15.5MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 348kB 15.5MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 358kB 15.5MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 368kB 15.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 378kB 15.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 389kB 15.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 399kB 15.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 409kB 15.5MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 419kB 15.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 430kB 15.5MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 440kB 15.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 450kB 15.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 460kB 15.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 471kB 15.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 481kB 15.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 491kB 15.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 501kB 15.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 512kB 15.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 522kB 15.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 532kB 15.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 542kB 15.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 552kB 15.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 563kB 15.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 573kB 15.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 583kB 15.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 593kB 15.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 604kB 15.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 614kB 15.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 624kB 15.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 634kB 15.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 645kB 15.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 655kB 15.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 665kB 15.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 675kB 15.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 686kB 15.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 696kB 15.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 706kB 15.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.12.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iHGs1J0pMOV"
      },
      "source": [
        "losses = tf.keras.losses.CategoricalCrossentropy(from_logits=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiSUuz__mXee",
        "outputId": "cf26cb66-6324-419e-d3c1-ade941fb1a89"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "train,test = tf.keras.datasets.mnist.load_data()\n",
        "x_train, y_train = train\n",
        "x_train = x_train[..., tf.newaxis] / 255.0\n",
        "\n",
        "# TFA layers and activations\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Conv2D(filters=10, kernel_size=(3,3),\n",
        "                         activation=tfa.activations.gelu),\n",
        "  tfa.layers.GroupNormalization(groups=5, axis=3),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# TFA optimizers, losses and metrics\n",
        "model.compile(\n",
        "    optimizer=tfa.optimizers.AdamW(0.01),\n",
        "    loss=tfa.losses.TripletSemiHardLoss(),\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train, epochs=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow_addons/activations/gelu.py:81: UserWarning: Default value of `approximate` is changed from `True` to `False`\n",
            "  \"Default value of `approximate` is changed from `True` to `False`\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.8846 - accuracy: 0.0955\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.8883 - accuracy: 0.0953\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.8727 - accuracy: 0.0873\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.7422 - accuracy: 0.0117\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.0000 - accuracy: 0.0769\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.0000 - accuracy: 0.1012\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.0000 - accuracy: 0.1012\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.0000 - accuracy: 0.1002\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.0000 - accuracy: 0.1009\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 1.0000 - accuracy: 0.1017\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZB40iH01lPXm"
      },
      "source": [
        "## CODE-3\n",
        "#####Trying on own"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZ2V7YXMoI5k"
      },
      "source": [
        "!wget 'https://github.com/OlafenwaMoses/IdenProf/releases/download/v1.0/idenprof-jpg.zip'\n",
        "!unzip '/content/idenprof-jpg.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKKkcBIAqg1u"
      },
      "source": [
        "# import the libraries as shown below\n",
        "\n",
        "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "#from keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
        "from tensorflow.keras.models import Sequential\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xl1KawLngbta"
      },
      "source": [
        "# !cp -r '/content/drive/MyDrive/Colab Notebooks/idenprof' '/content/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "935eyaovlZ9W"
      },
      "source": [
        "path = '/content/idenprof'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFntEc3LrVER"
      },
      "source": [
        "# useful for getting number of output classes\n",
        "folders = glob(path + '/train/*')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lfaqZDHqk8d"
      },
      "source": [
        "# re-size all the images to this\n",
        "IMAGE_SIZE = [224, 224]\n",
        "\n",
        "train_path = path + '/train'\n",
        "valid_path = path + '/test'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gB547Cxaqtpi"
      },
      "source": [
        "# Here we will be using imagenet weights\n",
        "\n",
        "vgg = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3DZJ5TwrIYg"
      },
      "source": [
        "# don't train existing weights(freeze layers)\n",
        "for layer in vgg.layers:\n",
        "    layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACcrGAV0rIdO"
      },
      "source": [
        "# our layers - you can add more if you want\n",
        "x = Flatten()(vgg.output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyCllqhxrIin"
      },
      "source": [
        "# last layer for vgg model with classes to predict\n",
        "prediction = Dense(len(folders), activation='softmax')(x)\n",
        "\n",
        "# create a model object\n",
        "model = Model(inputs=vgg.input, outputs=prediction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rv0k-aVlZ4f",
        "outputId": "64c62bf0-c87d-4271-d0ad-8c094bf66436"
      },
      "source": [
        "# view the structure of the model\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                250890    \n",
            "=================================================================\n",
            "Total params: 14,965,578\n",
            "Trainable params: 250,890\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJ-c-IWzlZ1x"
      },
      "source": [
        "# tell the model what cost and optimization method to use\n",
        "model.compile(\n",
        "  loss='categorical_crossentropy',\n",
        "  optimizer='adam',\n",
        "  metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYF28VEzlZqZ"
      },
      "source": [
        "### Optional step(as my data is good in lenght so not required)\n",
        "# Use the Image Data Generator to import the images from the dataset\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "                                  #  shear_range = 0.2,\n",
        "                                  #  zoom_range = 0.2,\n",
        "                                  #  horizontal_flip = True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CW2WoTxwsGvY",
        "outputId": "b34b8e28-a004-4cf1-a546-758c80329d07"
      },
      "source": [
        "# Make sure you provide the same target size as initialied for the image size\n",
        "training_set = train_datagen.flow_from_directory(train_path,\n",
        "                                                 target_size = (224, 224),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'categorical')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 9000 images belonging to 10 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jkeDMgBsPi6",
        "outputId": "e82a185c-60da-4855-85d3-257dc4093dac"
      },
      "source": [
        "test_set = test_datagen.flow_from_directory(valid_path,\n",
        "                                            target_size = (224, 224),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'categorical')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 10 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpTWb7kWsPoe",
        "outputId": "8bc2ae58-1fa9-4b94-d70b-037942c642de"
      },
      "source": [
        "# fit the model\n",
        "# Run the cell. It will take some time to execute\n",
        "r = model.fit_generator(\n",
        "  training_set,\n",
        "  validation_data=test_set,\n",
        "  epochs=10,\n",
        "  steps_per_epoch=len(training_set),\n",
        "  validation_steps=len(test_set)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "282/282 [==============================] - 53s 185ms/step - loss: 1.5409 - accuracy: 0.5182 - val_loss: 1.0635 - val_accuracy: 0.6805\n",
            "Epoch 2/10\n",
            "282/282 [==============================] - 45s 161ms/step - loss: 0.3993 - accuracy: 0.8674 - val_loss: 0.8487 - val_accuracy: 0.7365\n",
            "Epoch 3/10\n",
            "282/282 [==============================] - 46s 164ms/step - loss: 0.1777 - accuracy: 0.9537 - val_loss: 0.9493 - val_accuracy: 0.7285\n",
            "Epoch 4/10\n",
            "282/282 [==============================] - 46s 162ms/step - loss: 0.0927 - accuracy: 0.9849 - val_loss: 0.9258 - val_accuracy: 0.7355\n",
            "Epoch 5/10\n",
            "282/282 [==============================] - 46s 163ms/step - loss: 0.0455 - accuracy: 0.9972 - val_loss: 0.8686 - val_accuracy: 0.7545\n",
            "Epoch 6/10\n",
            "282/282 [==============================] - 46s 163ms/step - loss: 0.0315 - accuracy: 0.9981 - val_loss: 0.8606 - val_accuracy: 0.7610\n",
            "Epoch 7/10\n",
            "282/282 [==============================] - 46s 162ms/step - loss: 0.0268 - accuracy: 0.9981 - val_loss: 0.8848 - val_accuracy: 0.7600\n",
            "Epoch 8/10\n",
            "282/282 [==============================] - 46s 162ms/step - loss: 0.0196 - accuracy: 0.9985 - val_loss: 0.9396 - val_accuracy: 0.7565\n",
            "Epoch 9/10\n",
            "282/282 [==============================] - 46s 163ms/step - loss: 0.0177 - accuracy: 0.9989 - val_loss: 0.8854 - val_accuracy: 0.7635\n",
            "Epoch 10/10\n",
            "282/282 [==============================] - 46s 163ms/step - loss: 0.0090 - accuracy: 0.9998 - val_loss: 0.9543 - val_accuracy: 0.7565\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "NFI7-ETdsPuQ",
        "outputId": "9d15dce7-a468-445a-fc07-69665d8ba27e"
      },
      "source": [
        "# plot the loss\n",
        "plt.plot(r.history['loss'], label='train loss')\n",
        "plt.plot(r.history['val_loss'], label='val loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# plot the accuracy\n",
        "plt.plot(r.history['accuracy'], label='train acc')\n",
        "plt.plot(r.history['val_accuracy'], label='val acc')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hnz3Uz2UssFQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxTUOOLFthjZ"
      },
      "source": [
        "Validating how model is working "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYAZtSNYssOB"
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "model.save('model_vgg.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBHU3KRtaoZd"
      },
      "source": [
        "!cp '/content/model_vgg.h5' '/content/drive/MyDrive/Colab Notebooks'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEdEvl-iovB-"
      },
      "source": [
        "y_pred = model.predict(test_set)\n",
        "y_pred = np.argmax(y_pred, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6SSXfw1sscU"
      },
      "source": [
        "model=load_model('model_vgg.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qjZ_8_atAM4"
      },
      "source": [
        "img=image.load_img(path + '/test/police/police-103.jpg', target_size=(224,224))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nO9BWGpYtAV1",
        "outputId": "c0308695-2983-47da-9f69-4401b7822433"
      },
      "source": [
        "x=image.img_to_array(img)\n",
        "X=img\n",
        "x=x/255\n",
        "x.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(224, 224, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfRb4KjntAdC",
        "outputId": "12021cec-cad9-45e6-ce43-d3b6f019ef2b"
      },
      "source": [
        "x=np.expand_dims(x,axis=0)\n",
        "img_data=preprocess_input(x)\n",
        "img_data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 224, 224, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zY8VaapKtJHl",
        "outputId": "403e8dd9-6328-4918-aa29-101f4ae02041"
      },
      "source": [
        "model.predict(img_data)\n",
        "a=np.argmax(model.predict(img_data), axis=1)\n",
        "a"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    }
  ]
}